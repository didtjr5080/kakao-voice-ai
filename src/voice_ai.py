"""í†µí•© ìŒì„± ëŒ€í™” AI"""

from .parser import KakaoTalkParser
from .model import LightweightChatbot
from .stt import LightweightSTT
from .tts import LightweightTTS
from typing import Tuple, List, Dict

class VoiceConversationAI:
    """ìŒì„± ëŒ€í™” AI í†µí•© í´ë˜ìŠ¤ (STT â†’ Chatbot â†’ TTS)"""
    
    def __init__(
        self,
        model_name: str = "skt/kogpt2-base-v2",
        stt_model: str = "tiny",
        tts_rate: int = 150
    ):
        self.parser = KakaoTalkParser()
        self.chatbot = LightweightChatbot(model_name=model_name)
        self.stt = LightweightSTT(model_size=stt_model)
        self.tts = LightweightTTS(rate=tts_rate)
        
        self.is_trained = False
    
    def train_from_kakao(
        self,
        file_path: str,
        target_username: str,
        output_dir: str = "./models/kakao-chatbot",
        epochs: int = 3,
        context_window: int = 1
    ) -> str:
        """ì¹´ì¹´ì˜¤í†¡ íŒŒì¼ë¡œë¶€í„° í•™ìŠµ"""
        
        print("\n" + "="*70)
        print("ğŸ™ï¸ ìŒì„± ëŒ€í™” AI í•™ìŠµ ì‹œì‘")
        print("="*70)
        
        print("\nğŸ“š Step 1: ì¹´ì¹´ì˜¤í†¡ ëŒ€í™” íŒŒì‹±...")
        messages = self.parser.parse_file(file_path)
        
        if not messages:
            raise ValueError("íŒŒì‹±ëœ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        stats = self.parser.get_user_stats(messages)
        print(f"\n   ëŒ€í™” ì°¸ì—¬ì:")
        for user, count in stats.items():
            print(f"   - {user}: {count}ê°œ ë©”ì‹œì§€")
        
        print(f"\nğŸ“Š Step 2: '{target_username}' í•™ìŠµ ë°ì´í„° ìƒì„±...")
        training_pairs = self.parser.create_training_pairs(
            messages, 
            target_username,
            context_window
        )
        
        if not training_pairs:
            raise ValueError(f"'{target_username}' ì‚¬ìš©ìì˜ ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"   âœ“ {len(training_pairs)}ê°œ í•™ìŠµ ìŒ ìƒì„±")
        
        print("\n   ğŸ“ í•™ìŠµ ë°ì´í„° ìƒ˜í”Œ:")
        for i, (inp, out) in enumerate(training_pairs[:3], 1):
            print(f"   {i}. ì…ë ¥: {inp}")
            print(f"      ì‘ë‹µ: {out}")
        
        print(f"\nğŸ¤– Step 3: ëª¨ë¸ í•™ìŠµ...")
        model_path = self.chatbot.train(
            training_pairs=training_pairs,
            output_dir=output_dir,
            epochs=epochs,
            batch_size=1,
            use_lora=True
        )
        
        self.is_trained = True
        
        print(f"\nğŸ¤ Step 4: ìŒì„± ì‹œìŠ¤í…œ ë¡œë”©...")
        self.stt.load()
        self.tts.load()
        
        print("\n" + "="*70)
        print("âœ… ëª¨ë“  ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
        print("="*70 + "\n")
        
        return model_path
    
    def load_trained_model(self, model_path: str):
        """í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ"""
        print(f"ğŸ“‚ í•™ìŠµëœ ëª¨ë¸ ë¡œë”©: {model_path}")
        self.chatbot.load_model(model_path, use_lora=True)
        self.stt.load()
        self.tts.load()
        self.is_trained = True
        print("âœ… ëª¨ë“  ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
    
    def voice_chat(self, audio_path: str) -> Tuple[str, str, str]:
        """ìŒì„± ì…ë ¥ â†’ AI ì‘ë‹µ (ìŒì„±)"""
        
        if not self.is_trained:
            return "âš ï¸ ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµí•˜ê±°ë‚˜ ë¡œë“œí•´ì£¼ì„¸ìš”.", "", None
        
        user_text = self.stt.transcribe(audio_path)
        
        if user_text.startswith("[ìŒì„± ì¸ì‹ ì‹¤íŒ¨"):
            return user_text, "ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", None
        
        ai_response = self.chatbot.generate_response(user_text)
        ai_audio_path = self.tts.speak(ai_response)
        
        return user_text, ai_response, ai_audio_path
    
    def text_chat(self, user_text: str) -> Tuple[str, str]:
        """í…ìŠ¤íŠ¸ ì…ë ¥ â†’ AI ì‘ë‹µ (ìŒì„±)"""
        
        if not self.is_trained:
            return "âš ï¸ ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµí•˜ê±°ë‚˜ ë¡œë“œí•´ì£¼ì„¸ìš”.", None
        
        ai_response = self.chatbot.generate_response(user_text)
        ai_audio_path = self.tts.speak(ai_response)
        
        return ai_response, ai_audio_path
