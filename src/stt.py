"""ê²½ëŸ‰ ìŒì„± ì¸ì‹ (Whisper Tiny)"""

import torch
import whisper
from typing import Optional

class LightweightSTT:
    """ê²½ëŸ‰ ìŒì„± ì¸ì‹ ì—”ì§„ (VRAM ~400MB)"""
    
    def __init__(self, model_size: str = "tiny"):
        """
        Args:
            model_size: tiny, base, small ì¤‘ ì„ íƒ (tiny ê¶Œì¥)
        """
        self.model_size = model_size
        self.model = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
    
    def load(self):
        """Whisper ëª¨ë¸ ë¡œë“œ"""
        if self.model is None:
            print(f"ğŸ¤ Whisper {self.model_size} ëª¨ë¸ ë¡œë”©...")
            self.model = whisper.load_model(self.model_size, device=self.device)
            print(f"âœ… STT ì¤€ë¹„ ì™„ë£Œ (Device: {self.device})")
            
            if self.device == "cuda":
                vram = torch.cuda.memory_allocated() / 1024**3
                print(f"ğŸ’¾ VRAM ì‚¬ìš©ëŸ‰: {vram:.2f} GB")
    
    def transcribe(self, audio_path: str, language: str = "ko") -> str:
        """ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if self.model is None:
            self.load()
        
        try:
            result = self.model.transcribe(
                audio_path,
                language=language,
                fp16=(self.device == "cuda")
            )
            
            text = result["text"].strip()
            print(f"ğŸ¤ ì¸ì‹: {text}")
            return text
            
        except Exception as e:
            error_msg = f"[ìŒì„± ì¸ì‹ ì‹¤íŒ¨: {str(e)}]"
            print(f"âŒ {error_msg}")
            return error_msg
