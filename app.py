"""Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤"""

import gradio as gr
import os
import torch
from src.voice_ai import VoiceConversationAI

# ì „ì—­ AI ì¸ìŠ¤í„´ìŠ¤
voice_ai = VoiceConversationAI()

def get_vram_usage():
    """VRAM ì‚¬ìš©ëŸ‰ í™•ì¸"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        cached = torch.cuda.memory_reserved() / 1024**3
        return f"VRAM ì‚¬ìš©: {allocated:.2f} GB (ìºì‹œ: {cached:.2f} GB)"
    return "GPU ì—†ìŒ (CPU ëª¨ë“œ)"

def train_model(file, username, epochs, context_window):
    """í•™ìŠµ í•¸ë“¤ëŸ¬"""
    if file is None:
        return "âš ï¸ ì¹´ì¹´ì˜¤í†¡ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    if not username:
        return "âš ï¸ ì‚¬ìš©ì ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
    
    try:
        model_path = voice_ai.train_from_kakao(
            file.name,
            username.strip(),
            epochs=int(epochs),
            context_window=int(context_window)
        )
        
        vram_info = get_vram_usage()
        
        return f"""âœ… '{username}' í•™ìŠµ ì™„ë£Œ!

ğŸ“ ëª¨ë¸ ì €ì¥: {model_path}
ğŸ’¾ {vram_info}

ì´ì œ 'ìŒì„± ëŒ€í™”' íƒ­ì—ì„œ ëŒ€í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
"""
    except Exception as e:
        return f"âŒ í•™ìŠµ ì‹¤íŒ¨:\n{str(e)}"

def load_model(model_path):
    """ëª¨ë¸ ë¡œë“œ í•¸ë“¤ëŸ¬"""
    try:
        voice_ai.load_trained_model(model_path)
        vram_info = get_vram_usage()
        return f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\nğŸ’¾ {vram_info}"
    except Exception as e:
        return f"âŒ ë¡œë“œ ì‹¤íŒ¨: {str(e)}"

def voice_conversation(audio, history):
    """ìŒì„± ëŒ€í™” í•¸ë“¤ëŸ¬"""
    if audio is None:
        return history, None, ""
    
    user_text, ai_text, ai_audio = voice_ai.voice_chat(audio)
    
    history.append([f"ğŸ¤ {user_text}", f"ğŸ”Š {ai_text}"])
    
    return history, ai_audio, user_text

def text_conversation(message, history):
    """í…ìŠ¤íŠ¸ ëŒ€í™” í•¸ë“¤ëŸ¬"""
    if not message:
        return history, None
    
    ai_text, ai_audio = voice_ai.text_chat(message)
    
    history.append([message, f"ğŸ”Š {ai_text}"])
    
    return history, ai_audio

# Gradio ì•± êµ¬ì„±
with gr.Blocks(title="ê²½ëŸ‰ ìŒì„± ëŒ€í™” AI", theme=gr.themes.Soft()) as app:
    
    gr.Markdown("""
    # ğŸ™ï¸ ì¹´ì¹´ì˜¤í†¡ í•™ìŠµ ìŒì„± ëŒ€í™” AI
    ### VRAM 1.5GB ê²½ëŸ‰ ë²„ì „ - ë¡œì»¬ ì‹¤í–‰ ìµœì í™”
    
    ë§ˆì´í¬ë¡œ ë§í•˜ë©´ AIê°€ ë“£ê³  ìƒê°í•˜ê³  ë‹µí•©ë‹ˆë‹¤!
    """)
    
    with gr.Tab("ğŸ™ï¸ ìŒì„± ëŒ€í™”"):
        gr.Markdown("## ğŸ¤ ë§ˆì´í¬ë¡œ AIì™€ ëŒ€í™”í•˜ì„¸ìš”")
        
        chatbot = gr.Chatbot(label="ëŒ€í™” ê¸°ë¡", height=400)
        
        with gr.Row():
            with gr.Column(scale=1):
                audio_input = gr.Audio(
                    source="microphone",
                    type="filepath",
                    label="ğŸ¤ ë§ˆì´í¬ (ë…¹ìŒ ì‹œì‘)"
                )
                recognized_text = gr.Textbox(
                    label="ì¸ì‹ëœ ìŒì„±",
                    interactive=False,
                    lines=2
                )
            
            with gr.Column(scale=1):
                audio_output = gr.Audio(
                    label="ğŸ”Š AI ì‘ë‹µ ìŒì„±",
                    autoplay=True
                )
        
        audio_input.change(
            voice_conversation,
            [audio_input, chatbot],
            [chatbot, audio_output, recognized_text]
        )
    
    with gr.Tab("ğŸ’¬ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸"):
        gr.Markdown("### í…ìŠ¤íŠ¸ë¡œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸")
        
        test_chatbot = gr.Chatbot(label="ëŒ€í™”", height=400)
        
        with gr.Row():
            text_input = gr.Textbox(
                label="ë©”ì‹œì§€",
                placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
                scale=4
            )
            send_btn = gr.Button("ì „ì†¡", scale=1, variant="primary")
        
        test_audio = gr.Audio(label="ğŸ”Š AI ì‘ë‹µ ìŒì„±", autoplay=True)
        
        send_btn.click(
            text_conversation,
            [text_input, test_chatbot],
            [test_chatbot, test_audio]
        ).then(lambda: "", None, text_input)
        
        text_input.submit(
            text_conversation,
            [text_input, test_chatbot],
            [test_chatbot, test_audio]
        ).then(lambda: "", None, text_input)
    
    with gr.Tab("ğŸ“š ëª¨ë¸ í•™ìŠµ"):
        gr.Markdown("""
        ### ì¹´ì¹´ì˜¤í†¡ ëŒ€í™”ë¡œ AI í•™ìŠµí•˜ê¸°
        
        **ì¹´ì¹´ì˜¤í†¡ ëŒ€í™” ë‚´ë³´ë‚´ê¸°:**
        1. ì¹´ì¹´ì˜¤í†¡ ì•± â†’ ëŒ€í™”ë°© ì—´ê¸°
        2. ìš°ì¸¡ ìƒë‹¨ `â‰¡` â†’ **ëŒ€í™” ë‚´ë³´ë‚´ê¸°**
        3. **í…ìŠ¤íŠ¸ë§Œ** ì„ íƒ â†’ ì €ì¥
        4. ì•„ë˜ì— ì—…ë¡œë“œ
        """)
        
        with gr.Row():
            with gr.Column():
                kakao_file = gr.File(
                    label="ğŸ“‚ ì¹´ì¹´ì˜¤í†¡ ëŒ€í™” íŒŒì¼ (.txt)",
                    file_types=[".txt"]
                )
                target_user = gr.Textbox(
                    label="ğŸ¯ í•™ìŠµí•  ì‚¬ìš©ì ì´ë¦„",
                    placeholder="ì˜ˆ: ì–‘ì„"
                )
            
            with gr.Column():
                epochs_slider = gr.Slider(
                    minimum=1, maximum=10, value=3, step=1,
                    label="í•™ìŠµ ì—í­ ìˆ˜"
                )
                context_slider = gr.Slider(
                    minimum=1, maximum=5, value=1, step=1,
                    label="ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°"
                )
        
        train_btn = gr.Button("ğŸš€ í•™ìŠµ ì‹œì‘", variant="primary", size="lg")
        train_status = gr.Textbox(label="í•™ìŠµ ìƒíƒœ", lines=10, interactive=False)
        
        train_btn.click(
            train_model,
            [kakao_file, target_user, epochs_slider, context_slider],
            train_status
        )
    
    with gr.Tab("âš™ï¸ ì„¤ì •"):
        gr.Markdown("### ê¸°ì¡´ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°")
        
        model_path_input = gr.Textbox(
            label="ëª¨ë¸ ê²½ë¡œ",
            value="./models/kakao-chatbot"
        )
        load_btn = gr.Button("ğŸ“‚ ëª¨ë¸ ë¡œë“œ", variant="secondary")
        load_status = gr.Textbox(label="ìƒíƒœ", lines=5)
        
        load_btn.click(load_model, model_path_input, load_status)
        
        gr.Markdown(f"""
        ---
        ### ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´
        
        - **ì±—ë´‡**: KoGPT-2 (4bit ì–‘ìí™” + LoRA)
        - **STT**: Whisper Tiny (~400MB VRAM)
        - **TTS**: pyttsx3 (ì˜¤í”„ë¼ì¸, CPU)
        - **í˜„ì¬**: {get_vram_usage()}
        
        ### ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª©í‘œ
        - í•™ìŠµ ì‹œ: ìµœëŒ€ 1.5GB VRAM
        - ì¶”ë¡  ì‹œ: ìµœëŒ€ 1GB VRAM
        """)

if __name__ == "__main__":
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )
